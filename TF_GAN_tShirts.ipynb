{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0c931ba401747e1100110d99c7b2e1195adf3961a7e00160e720e39c4d164b397",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "afa55092dc2bf38ba6aef7cffc57f3306e69ad8765fa36c252346589134cf799"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\brad\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.32.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (3.15.6)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (0.35.1)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.28.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (50.3.1.post20201107)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorboard~=2.4->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\brad\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: tensorflow-gan in c:\\users\\brad\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: tensorflow-hub>=0.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-gan) (0.11.0)\n",
      "Requirement already satisfied: tensorflow-probability>=0.7 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-gan) (0.12.1)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (3.15.6)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-hub>=0.2->tensorflow-gan) (1.19.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (4.4.2)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.15.0)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.1.5)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (1.6.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.7->tensorflow-gan) (0.3.3)\n",
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\brad\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.24.0)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (3.15.6)\n",
      "Requirement already satisfied: dill in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.3.3)\n",
      "Requirement already satisfied: promise in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: termcolor in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.29.0)\n",
      "Requirement already satisfied: six in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.12.0)\n",
      "Requirement already satisfied: future in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (0.18.2)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (5.1.2)\n",
      "Requirement already satisfied: attrs>=18.1.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (20.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (4.50.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-datasets) (1.19.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.53.0)\n",
      "Requirement already satisfied: keras in c:\\users\\brad\\anaconda3\\lib\\site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from keras) (1.19.2)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from keras) (1.5.2)\n",
      "Requirement already satisfied: h5py in c:\\users\\brad\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\brad\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\brad\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\brad\\anaconda3\\lib\\site-packages (4.5.1.48)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\brad\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "WARNING:tensorflow:From C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_gan\\python\\estimator\\tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that imports for the rest of the file work.\n",
    "!pip install tensorflow\n",
    "!pip install tensorflow-gan\n",
    "!pip install tensorflow-datasets\n",
    "!pip install keras\n",
    "!pip install opencv-python\n",
    "import tensorflow.compat.v1 as tf\n",
    "import tensorflow_gan as tfgan\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Allow matplotlib images to render immediately.\n",
    "%matplotlib inline\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # Disable noisy outputs.\n",
    "#evaluates operations immediately without building graphs\n",
    "\n",
    "tf.disable_v2_behavior()\n",
    "tf.compat.v1.enable_resource_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "shirtDir = os.listdir(\"SixDollarImages/\")\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.compat.v1 as tf\n",
    "import gc\n",
    "import cv2\n",
    "\n",
    "g = tf.Graph()\n",
    "\n",
    "# with tf.Session(graph=g) as session:\n",
    "def input_fn(mode, params):\n",
    "\n",
    "  shirtListTrain = []\n",
    "  shirtListTest = []\n",
    "  index = 0\n",
    "\n",
    "  for file in shirtDir:\n",
    "    im = Image.open(\"SixDollarImages/\" + file)\n",
    "    im = im.resize((112, 112))\n",
    "    # im = im.resize((28, 28))\n",
    "    # im = im.convert(\"RGB\")\n",
    "    im = im.convert(\"RGB\")\n",
    "\n",
    "    # im = cv2.imread(\"SixDollarImages/\" + file)\n",
    "    # im = cv2.resize(im, (128, 128))\n",
    "    # im = cv2.cvtColor(im, cv2.COLOR_RBGA2RGB)\n",
    "\n",
    "    im = np.array(im).reshape((112, 112, 3))\n",
    "    # im = np.array(im).reshape((28, 28, 3))\n",
    "    im = tf.convert_to_tensor(im, dtype=tf.uint8)\n",
    "\n",
    "    if index < 20:\n",
    "        shirtListTrain.append(im)\n",
    "    else:\n",
    "        # shirtListTest.append(np.asarray(im))\n",
    "        shirtListTest.append(im)\n",
    "    del im\n",
    "    index = index + 1\n",
    "\n",
    "  assert 'batch_size' in params\n",
    "  assert 'noise_dims' in params\n",
    "  bs = params['batch_size']\n",
    "  nd = params['noise_dims']\n",
    "  split = 'train' if mode == tf.estimator.ModeKeys.TRAIN else 'test'\n",
    "  shuffle = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  just_noise = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "  \n",
    "  #for each tensor call tf.random_normal\n",
    "  #lambda is an unnamed python function \n",
    "  # _ is used to ignore certian values, here we are ignoring the index\n",
    "  noise_ds = (tf.data.Dataset.from_tensors(0).repeat()\n",
    "              .map(lambda _: tf.random_normal([bs, nd])))\n",
    "  \n",
    "  if just_noise:\n",
    "    return noise_ds\n",
    "  \n",
    "  #define everything as tensors\n",
    "  def process_path(tensorInput):\n",
    "    #{'image': <tf.Tensor 'args_0:0' shape=(28, 28, 1) dtype=uint8>, 'label': <tf.Tensor 'args_1:0' shape=() dtype=int64>}\n",
    "    #Step 1\n",
    "    print(\"Step 1\")\n",
    "    print(tensorInput)\n",
    "\n",
    "    image = (tf.cast(tensorInput, tf.float32) - 127.5) / 127.5\n",
    "    #Tensor(\"truediv:0\", shape=(28, 28, 1), dtype=float32)\n",
    "    #Step 2\n",
    "    print(\"Step 2\")\n",
    "    print(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "  datasetTrain = tf.data.Dataset.from_tensor_slices(shirtListTrain)\n",
    "  datasetTest = tf.data.Dataset.from_tensor_slices(shirtListTest)\n",
    "\n",
    "  if split == 'train':\n",
    "    #returns a map() object (which is an iterator)\n",
    "    #stores data in a temporary location instead of retrieving from source everytime\n",
    "    \n",
    "    images_ds = datasetTrain.map(process_path)\n",
    "      \n",
    "  else:\n",
    "    images_ds = datasetTest.map(process_path)\n",
    "\n",
    "  if shuffle:\n",
    "    images_ds = images_ds.shuffle(\n",
    "        buffer_size=5, reshuffle_each_iteration=True)\n",
    "  images_ds = (images_ds.batch(bs, drop_remainder=True)\n",
    "              .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "\n",
    "\n",
    "  # <PrefetchDataset shapes: (5, 28, 28, 1), types: tf.float32>\n",
    "  # Step 3\n",
    "  print(\"Step 3\")\n",
    "  print(images_ds)\n",
    "  return tf.data.Dataset.zip((noise_ds, images_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import tensorflow_datasets as tfds\n",
    "# import tensorflow_gan as tfgan\n",
    "# import numpy as np\n",
    "\n",
    "# params = {'batch_size': 100, 'noise_dims':64}\n",
    "# with tf.Graph().as_default():\n",
    "#   ds = input_fn(tf.estimator.ModeKeys.TRAIN, params)\n",
    "#   numpy_imgs = next(iter(tfds.as_numpy(ds)))[1]\n",
    "# img_grid = tfgan.eval.python_image_grid(numpy_imgs, grid_shape=(10, 10))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(np.squeeze(img_grid))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dense(inputs, units, l2_weight):\n",
    "  # print(\"Step 4\")\n",
    "  # print(inputs)\n",
    "  # print(\"units\")\n",
    "  # print(units)\n",
    "  # print(\"weight\")\n",
    "  # print(l2_weight)\n",
    "  return tf.layers.dense(\n",
    "      inputs, units, None,\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
    "\n",
    "def _batch_norm(inputs, is_training):\n",
    "  return tf.layers.batch_normalization(\n",
    "      inputs, momentum=0.999, epsilon=0.001, training=is_training)\n",
    "\n",
    "def _deconv2d(inputs, filters, kernel_size, stride, l2_weight):\n",
    "  return tf.layers.conv2d_transpose(\n",
    "      inputs, filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
    "      activation=tf.nn.relu, padding='same',\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
    "\n",
    "def _conv2d(inputs, filters, kernel_size, stride, l2_weight):\n",
    "  # print(\"conv2d input\")\n",
    "  # print(inputs)\n",
    "  return tf.layers.conv2d(\n",
    "      inputs, filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
    "      activation=None, padding='same',\n",
    "      kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "      kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "      bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))\n",
    "    \n",
    "  # print(\"conv2d input\")\n",
    "  # print(inputs)\n",
    "  # return tf.keras.layers.Conv2D(\n",
    "  #     inputs, filters, [kernel_size, kernel_size], strides=[stride, stride], \n",
    "  #     activation=None, padding='same',\n",
    "  #     kernel_initializer=tf.keras.initializers.glorot_uniform,\n",
    "  #     kernel_regularizer=tf.keras.regularizers.l2(l=l2_weight),\n",
    "  #     bias_regularizer=tf.keras.regularizers.l2(l=l2_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unconditional_generator(noise, mode, weight_decay=2.5e-5):\n",
    "  \"\"\"Generator to produce unconditional MNIST images.\"\"\"\n",
    "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    " \n",
    "  net = _dense(noise, 1024, weight_decay)\n",
    "  net = _batch_norm(net, is_training)\n",
    "  net = tf.nn.relu(net)\n",
    "  \n",
    "  net = _dense(net, 28 * 28 * 256, weight_decay)\n",
    "  net = _batch_norm(net, is_training)\n",
    "  net = tf.nn.relu(net)\n",
    "  \n",
    "  net = tf.reshape(net, [-1, 28, 28, 256])\n",
    "\n",
    "  net = _deconv2d(net, 64, 4, 2, weight_decay)\n",
    "  net = _deconv2d(net, 64, 4, 2, weight_decay)\n",
    "  # Make sure that generator output is in the same range as `inputs`\n",
    "  # ie [-1, 1].\n",
    "  net = _conv2d(net, 3, 4, 1, 0.0)\n",
    "\n",
    "  net = tf.tanh(net)\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_leaky_relu = lambda net: tf.nn.leaky_relu(net, alpha=0.01)\n",
    "\n",
    "def unconditional_discriminator(img, unused_conditioning, mode, weight_decay=2.5e-5):\n",
    "  del unused_conditioning\n",
    "  is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    "  # print(\"disc img\")\n",
    "  # print(img)\n",
    "  net = _conv2d(img, 64, 4, 2, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _conv2d(net, 128, 4, 2, weight_decay)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = tf.layers.flatten(net)\n",
    "  \n",
    "  net = _dense(net, 256, weight_decay)\n",
    "  net = _batch_norm(net, is_training)\n",
    "  net = _leaky_relu(net)\n",
    "  \n",
    "  net = _dense(net, 1, weight_decay)\n",
    "\n",
    "  return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inception score with Keras\n",
    "from math import floor\n",
    "from numpy import ones\n",
    "from numpy import expand_dims\n",
    "from numpy import log\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import exp\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "import tensorflow_hub as tfhub\n",
    "\n",
    "INCEPTION_MODULE = \"https://tfhub.dev/google/imagenet/inception_v3/classification/5\"\n",
    "\n",
    "def calculate_inception_score(images, n_split=1, eps=1E-16):\n",
    "    processed = preprocess_input(images)\n",
    "\n",
    "    inception_classifier_fn = tfhub.load(INCEPTION_MODULE)\n",
    "    score = tfgan.eval.classifier_score(processed, inception_classifier_fn, 1)\n",
    "    score.shape.assert_is_compatible_with([])\n",
    "    \n",
    "    return score\n",
    "\n",
    "def calculate_frechet_distance(real_images, generated_images, num_batches=1):\n",
    "   \n",
    "    inception_classifier_fn = tfhub.load(INCEPTION_MODULE)\n",
    "    frechet_distance = tfgan.eval.frechet_classifier_distance(real_images, generated_images, inception_classifier_fn, num_batches)\n",
    "    frechet_distance.shape.assert_is_compatible_with([])\n",
    "\n",
    "    return frechet_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_gan.examples.mnist import util as eval_util\n",
    "import os\n",
    "\n",
    "def get_eval_metric_ops_fn(gan_model):\n",
    "  real_data_logits = tf.reduce_mean(gan_model.discriminator_real_outputs)\n",
    "  gen_data_logits = tf.reduce_mean(gan_model.discriminator_gen_outputs)\n",
    "  \n",
    "  real_mnist_score = calculate_inception_score(gan_model.real_data)\n",
    "  generated_mnist_score = calculate_inception_score(gan_model.generated_data)\n",
    "  \n",
    "  frechet_distance = calculate_frechet_distance(\n",
    "      gan_model.real_data, gan_model.generated_data)\n",
    "\n",
    "  fullObj =  {\n",
    "      'real_data_logits': tf.metrics.mean(real_data_logits),\n",
    "      'gen_data_logits': tf.metrics.mean(gen_data_logits),\n",
    "      'real_mnist_score': tf.metrics.mean(real_mnist_score),\n",
    "      'mnist_score': tf.metrics.mean(generated_mnist_score),\n",
    "      'frechet_distance': tf.metrics.mean(frechet_distance),\n",
    "  }\n",
    "  print(fullObj)\n",
    "  return {\n",
    "      'real_data_logits': tf.metrics.mean(real_data_logits),\n",
    "      'gen_data_logits': tf.metrics.mean(gen_data_logits),\n",
    "      'real_mnist_score': tf.metrics.mean(real_mnist_score),\n",
    "      'mnist_score': tf.metrics.mean(generated_mnist_score),\n",
    "      'frechet_distance': tf.metrics.mean(frechet_distance),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 5 #@param\n",
    "noise_dimensions = 64 #@param\n",
    "generator_lr = 0.001 #@param\n",
    "discriminator_lr = 0.0002 #@param\n",
    "\n",
    "def gen_opt():\n",
    "  gstep = tf.train.get_or_create_global_step()\n",
    "  base_lr = generator_lr\n",
    "  # Halve the learning rate at 1000 steps.\n",
    "  lr = tf.cond(gstep < 1000, lambda: base_lr, lambda: base_lr / 2.0)\n",
    "  return tf.train.AdamOptimizer(lr, 0.5)\n",
    "\n",
    "gan_estimator = tfgan.estimator.GANEstimator(\n",
    "    generator_fn=unconditional_generator,\n",
    "    discriminator_fn=unconditional_discriminator,\n",
    "    generator_loss_fn=tfgan.losses.wasserstein_generator_loss,\n",
    "    discriminator_loss_fn=tfgan.losses.wasserstein_discriminator_loss,\n",
    "    params={'batch_size': train_batch_size, 'noise_dims': noise_dimensions},\n",
    "    generator_optimizer=gen_opt,\n",
    "    discriminator_optimizer=tf.train.AdamOptimizer(discriminator_lr, 0.5),\n",
    "    get_eval_metric_ops_fn=get_eval_metric_ops_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "executing eargerly\n",
      "False\n",
      "train\n",
      "Step 1\n",
      "Tensor(\"args_0:0\", shape=(112, 112, 3), dtype=uint8)\n",
      "Step 2\n",
      "Tensor(\"truediv:0\", shape=(112, 112, 3), dtype=float32)\n",
      "Step 3\n",
      "<DatasetV1Adapter shapes: (5, 112, 112, 3), types: tf.float32>\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  warnings.warn('`layer.apply` is deprecated and '\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\normalization.py:307: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:1294: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "  warnings.warn('`tf.layers.conv2d_transpose` is deprecated and '\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\convolutional.py:414: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
      "  warnings.warn('`tf.layers.conv2d` is deprecated and '\n",
      "C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\legacy_tf_layers\\core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
      "Time since start: 0.59 min\n",
      "Trained from step 0 to 500 in 14.21 steps / sec\n",
      "evaluate\n",
      "Step 1\n",
      "Tensor(\"args_0:0\", shape=(112, 112, 3), dtype=uint8)\n",
      "Step 2\n",
      "Tensor(\"truediv:0\", shape=(112, 112, 3), dtype=float32)\n",
      "Step 3\n",
      "<DatasetV1Adapter shapes: (5, 112, 112, 3), types: tf.float32>\n",
      "{'real_data_logits': (<tf.Tensor 'metrics/mean_10/value:0' shape=() dtype=float32>, <tf.Tensor 'metrics/mean_10/update_op:0' shape=() dtype=float32>), 'gen_data_logits': (<tf.Tensor 'metrics/mean_11/value:0' shape=() dtype=float32>, <tf.Tensor 'metrics/mean_11/update_op:0' shape=() dtype=float32>), 'real_mnist_score': (<tf.Tensor 'metrics/mean_12/value:0' shape=() dtype=float32>, <tf.Tensor 'metrics/mean_12/update_op:0' shape=() dtype=float32>), 'mnist_score': (<tf.Tensor 'metrics/mean_13/value:0' shape=() dtype=float32>, <tf.Tensor 'metrics/mean_13/update_op:0' shape=() dtype=float32>), 'frechet_distance': (<tf.Tensor 'metrics/mean_14/value:0' shape=() dtype=float32>, <tf.Tensor 'metrics/mean_14/update_op:0' shape=() dtype=float32>)}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey metrics/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1640) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-c4a8c1820524>\", line 35, in <module>\n    metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 461, in evaluate\n    return self._actual_eval(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 510, in _actual_eval\n    return _evaluate()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 493, in _evaluate\n    return self._evaluate_run(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1640, in _evaluate_run\n    eval_results = evaluation._evaluate_once(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 268, in _evaluate_once\n    with monitored_session.MonitoredSession(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1034, in __init__\n    super(MonitoredSession, self).__init__(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 749, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1231, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1236, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 902, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 660, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 235, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 606, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in __init__\n    self.build()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 847, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 382, in _AddShardedRestoreOps\n    self._AddRestoreOps(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 334, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 582, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1507, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1374\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1375\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1376\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[0;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                           run_metadata):\n\u001b[1;32m-> 1451\u001b[1;33m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[0;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key metrics/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta not found in checkpoint\n\t [[{{node save/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1296\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         sess.run(self.saver_def.restore_op_name,\n\u001b[0m\u001b[0;32m   1298\u001b[0m                  {self.saver_def.filename_tensor_name: save_path})\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 967\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    968\u001b[0m                          run_metadata_ptr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1190\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1368\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1369\u001b[0m                            run_metadata)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[1;32m-> 1394\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key metrics/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1640) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-c4a8c1820524>\", line 35, in <module>\n    metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 461, in evaluate\n    return self._actual_eval(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 510, in _actual_eval\n    return _evaluate()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 493, in _evaluate\n    return self._evaluate_run(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1640, in _evaluate_run\n    eval_results = evaluation._evaluate_once(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 268, in _evaluate_once\n    with monitored_session.MonitoredSession(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1034, in __init__\n    super(MonitoredSession, self).__init__(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 749, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1231, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1236, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 902, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 660, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 235, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 606, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in __init__\n    self.build()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 847, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 382, in _AddShardedRestoreOps\n    self._AddRestoreOps(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 334, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 582, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1507, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m     68\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m     return CheckpointReader.CheckpointReader_GetTensor(\n\u001b[0m\u001b[0;32m     70\u001b[0m         self, compat.as_bytes(tensor_str))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1307\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m         \u001b[0mnames_to_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[1;34m(checkpoint_path)\u001b[0m\n\u001b[0;32m   1625\u001b[0m   \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpy_checkpoint_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m   \u001b[0mobject_graph_string\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOBJECT_GRAPH_PROTO_KEY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m   \u001b[0mobject_graph_proto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrackable_object_graph_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrackableObjectGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36mget_tensor\u001b[1;34m(self, tensor_str)\u001b[0m\n\u001b[0;32m     73\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m     \u001b[0merror_translator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\py_checkpoint_reader.py\u001b[0m in \u001b[0;36merror_translator\u001b[1;34m(e)\u001b[0m\n\u001b[0;32m     34\u001b[0m       'matching files for') in error_message:\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m   elif 'Sliced checkpoints are not supported' in error_message or (\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c4a8c1820524>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m   \u001b[1;31m# Calculate some metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"evaluate\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m   \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatches_for_eval_metrics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m   \u001b[0msteps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcur_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m   \u001b[0mreal_logits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'real_data_logits'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, input_fn, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m       return self._actual_eval(\n\u001b[0m\u001b[0;32m    462\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    463\u001b[0m           \u001b[0mstrategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eval_distribution\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_actual_eval\u001b[1;34m(self, input_fn, strategy, steps, hooks, checkpoint_path, name)\u001b[0m\n\u001b[0;32m    508\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 510\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_convert_eval_steps_to_hooks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    491\u001b[0m         (scaffold, update_op, eval_dict, all_hooks) = (\n\u001b[0;32m    492\u001b[0m             self._evaluate_build_graph(input_fn, hooks, checkpoint_path))\n\u001b[1;32m--> 493\u001b[1;33m         return self._evaluate_run(\n\u001b[0m\u001b[0;32m    494\u001b[0m             \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mscaffold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscaffold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_evaluate_run\u001b[1;34m(self, checkpoint_path, scaffold, update_op, eval_dict, all_hooks, output_dir)\u001b[0m\n\u001b[0;32m   1638\u001b[0m                     all_hooks, output_dir):\n\u001b[0;32m   1639\u001b[0m     \u001b[1;34m\"\"\"Run evaluation.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1640\u001b[1;33m     eval_results = evaluation._evaluate_once(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   1641\u001b[0m         \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m         \u001b[0mmaster\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation_master\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\u001b[0m in \u001b[0;36m_evaluate_once\u001b[1;34m(checkpoint_path, master, scaffold, eval_ops, feed_dict, final_ops, final_ops_feed_dict, hooks, config)\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinal_ops_hook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m   with monitored_session.MonitoredSession(\n\u001b[0m\u001b[0;32m    269\u001b[0m       session_creator=session_creator, hooks=hooks) as session:\n\u001b[0;32m    270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meval_ops\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m                \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m                stop_grace_period_secs=120):\n\u001b[1;32m-> 1034\u001b[1;33m     super(MonitoredSession, self).__init__(\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[0msession_creator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m         \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    747\u001b[0m         stop_grace_period_secs=stop_grace_period_secs)\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshould_recover\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_RecoverableSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    750\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_coordinated_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1229\u001b[0m     \"\"\"\n\u001b[0;32m   1230\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess_creator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1231\u001b[1;33m     \u001b[0m_WrappedSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1233\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_create_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36m_create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1235\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1236\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sess_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1237\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m         logging.info(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    900\u001b[0m       \u001b[1;34m\"\"\"Creates a coordinated session.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    901\u001b[0m       \u001b[1;31m# Keep the tf_sess for unit testing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 902\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_sess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_creator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    903\u001b[0m       \u001b[1;31m# We don't want coordinator to suppress any exception.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoordinator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCoordinator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclean_stop_exception_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\u001b[0m in \u001b[0;36mcreate_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    659\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcreate_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 661\u001b[1;33m     return self._get_session_manager().prepare_session(\n\u001b[0m\u001b[0;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_master\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m         \u001b[0msaver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scaffold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36mprepare_session\u001b[1;34m(self, master, init_op, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config, init_feed_dict, init_fn)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \"\"\"\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m     sess, is_loaded_from_checkpoint = self._restore_checkpoint(\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[0mmaster\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m         \u001b[0msaver\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\session_manager.py\u001b[0m in \u001b[0;36m_restore_checkpoint\u001b[1;34m(self, master, saver, checkpoint_dir, checkpoint_filename_with_path, wait_for_checkpoint, max_wait_secs, config)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m       \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_filename_with_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1311\u001b[0m         \u001b[1;31m# is a graph mismatch. Re-raise the original error with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1312\u001b[0m         \u001b[1;31m# a helpful message (b/110263146)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1313\u001b[1;33m         raise _wrap_restore_error_with_msg(\n\u001b[0m\u001b[0;32m   1314\u001b[0m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey metrics/InceptionV3/Conv2d_1a_3x3/BatchNorm/beta not found in checkpoint\n\t [[node save/RestoreV2 (defined at C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1640) ]]\n\nOriginal stack trace for 'save/RestoreV2':\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 845, in launch_instance\n    app.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 612, in start\n    self.io_loop.start()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n    self._run_once()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n    handle._run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n    self._context.run(self._callback, *self._args)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n    self.run()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 365, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 543, in execute_request\n    self.do_execute(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 306, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2877, in run_cell\n    result = self._run_cell(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2923, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3146, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n    if (await self.run_code(code, result,  async_=asy)):\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3418, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-c4a8c1820524>\", line 35, in <module>\n    metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 461, in evaluate\n    return self._actual_eval(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 510, in _actual_eval\n    return _evaluate()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 493, in _evaluate\n    return self._evaluate_run(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\", line 1640, in _evaluate_run\n    eval_results = evaluation._evaluate_once(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\evaluation.py\", line 268, in _evaluate_once\n    with monitored_session.MonitoredSession(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1034, in __init__\n    super(MonitoredSession, self).__init__(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 749, in __init__\n    self._sess = _RecoverableSession(self._coordinated_creator)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1231, in __init__\n    _WrappedSession.__init__(self, self._create_session())\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 1236, in _create_session\n    return self._sess_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 902, in create_session\n    self.tf_sess = self._session_creator.create_session()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 660, in create_session\n    self._scaffold.finalize()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py\", line 235, in finalize\n    self._saver = training_saver._get_saver_or_default()  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 606, in _get_saver_or_default\n    saver = Saver(sharded=True, allow_empty=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in __init__\n    self.build()\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 847, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 875, in _build\n    self.saver_def = self._builder._build_internal(  # pylint: disable=protected-access\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 508, in _build_internal\n    restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 382, in _AddShardedRestoreOps\n    self._AddRestoreOps(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 334, in _AddRestoreOps\n    all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 582, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1507, in restore_v2\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 748, in _apply_op_helper\n    op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3528, in _create_op_internal\n    ret = Operation(\n  File \"C:\\Users\\Brad\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1990, in __init__\n    self._traceback = tf_stack.extract_stack()\n"
     ]
    }
   ],
   "source": [
    "# Disable noisy output.\n",
    "tf.autograph.set_verbosity(0, False)\n",
    "\n",
    "import time\n",
    "steps_per_eval = 500 #@param\n",
    "max_train_steps = 5000 #@param\n",
    "batches_for_eval_metrics = 5 #@param\n",
    "\n",
    "# Used to track metrics.\n",
    "steps = []\n",
    "real_logits, fake_logits = [], []\n",
    "real_mnist_scores, mnist_scores, frechet_distances = [], [], []\n",
    "\n",
    "cur_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"executing eargerly\")\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "while cur_step < max_train_steps:\n",
    "  next_step = min(cur_step + steps_per_eval, max_train_steps)\n",
    "\n",
    "  start = time.time()\n",
    "  print(\"train\")\n",
    "  gan_estimator.train(input_fn, max_steps=next_step)\n",
    "  steps_taken = next_step - cur_step\n",
    "  time_taken = time.time() - start\n",
    "  print('Time since start: %.2f min' % ((time.time() - start_time) / 60.0))\n",
    "  print('Trained from step %i to %i in %.2f steps / sec' % (\n",
    "      cur_step, next_step, steps_taken / time_taken))\n",
    "  cur_step = next_step\n",
    "  \n",
    "  # Calculate some metrics.\n",
    "  print(\"evaluate\")\n",
    "  metrics = gan_estimator.evaluate(input_fn, steps=batches_for_eval_metrics)\n",
    "  steps.append(cur_step)\n",
    "  real_logits.append(metrics['real_data_logits'])\n",
    "  fake_logits.append(metrics['gen_data_logits'])\n",
    "  real_mnist_scores.append(metrics['real_mnist_score'])\n",
    "  mnist_scores.append(metrics['mnist_score'])\n",
    "  frechet_distances.append(metrics['frechet_distance'])\n",
    "  print('Average discriminator output on Real: %.2f  Fake: %.2f' % (\n",
    "      real_logits[-1], fake_logits[-1]))\n",
    "  print('Inception Score: %.2f / %.2f  Frechet Distance: %.2f' % (\n",
    "      mnist_scores[-1], real_mnist_scores[-1], frechet_distances[-1]))\n",
    "  \n",
    "  # Vizualize some images.\n",
    "  print(\"predict\")\n",
    "  iterator = gan_estimator.predict(\n",
    "      input_fn, hooks=[tf.train.StopAtStepHook(num_steps=21)])\n",
    "  try:\n",
    "    imgs = np.array([next(iterator) for _ in range(20)])\n",
    "  except StopIteration:\n",
    "    pass\n",
    "  tiled = tfgan.eval.python_image_grid(imgs, grid_shape=(2, 10))\n",
    "  plt.axis('off')\n",
    "  plt.imshow(np.squeeze(tiled))\n",
    "  plt.show()\n",
    "  \n",
    "  \n",
    "# Plot the metrics vs step.\n",
    "plt.title('MNIST Frechet distance per step')\n",
    "plt.plot(steps, frechet_distances)\n",
    "plt.figure()\n",
    "plt.title('MNIST Score per step')\n",
    "plt.plot(steps, mnist_scores)\n",
    "plt.plot(steps, real_mnist_scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}